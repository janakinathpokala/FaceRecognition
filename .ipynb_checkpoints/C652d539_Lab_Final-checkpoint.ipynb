{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QRJXuAdL9MY3"
   },
   "source": [
    "**Answer 1:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "colab_type": "code",
    "id": "ckMyAA3p3-sJ",
    "outputId": "6d9daaae-b474-438e-c3f5-029db704d66e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.6/dist-packages (2.2.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.10.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.2.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.9.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n",
      "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.2.1)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.2.1)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.34.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.18.4)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.28.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-gpu) (46.1.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.2.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (2.23.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.6.0.post3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (0.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.7.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (2020.4.5.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (4.0)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mpZMfikU5CYS"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as ks\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "onBkCwKR5Ukz"
   },
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oKnn_XJ66OZZ",
    "outputId": "bc827043-7a7d-41bb-bd1f-27ec1bd4c1b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ti_WXWiv6arM"
   },
   "outputs": [],
   "source": [
    "y_train=ks.utils.to_categorical(y_train)\n",
    "y_test=ks.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vjrfZntz7Eiz",
    "outputId": "697a11e7-b792-4cd1-b6b7-d39ab7dd8906"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yl7TdbTk8kUR"
   },
   "outputs": [],
   "source": [
    "x_train=x_train/255.\n",
    "x_test=x_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_mkCKkmcJfeS"
   },
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "    \n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    F1, F2, F3 = filters\n",
    "     \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First \n",
    "    X = ks.layers.Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'same', name = conv_name_base + '2a', kernel_initializer ='he_normal')(X)\n",
    "    X = ks.layers.BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = ks.layers.Activation('relu')(X)\n",
    "    \n",
    "    \n",
    "    # Second \n",
    "    X = ks.layers.Conv2D(filters=F2,kernel_size=(f,f),strides=(1,1),padding='same',name=conv_name_base+'2b',kernel_initializer='he_normal')(X)\n",
    "    X = ks.layers.BatchNormalization(axis=3,name=bn_name_base+'2b')(X)\n",
    "    X = ks.layers.Activation('relu')(X)\n",
    "\n",
    "    # Third \n",
    "    X = ks.layers.Conv2D(filters=F3,kernel_size=(1,1),strides=(1,1),padding='same',name=conv_name_base+'2c',kernel_initializer='he_normal')(X)\n",
    "    X = ks.layers.BatchNormalization(axis=3,name=bn_name_base+'2c')(X)\n",
    "\n",
    "    #  Add shortcut\n",
    "    X = ks.layers.Add()([X_shortcut,X])\n",
    "    X = ks.layers.Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3UOajGJqOmwK"
   },
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    \n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    X_shortcut = X\n",
    "\n",
    "    # First\n",
    "    X = ks.layers.Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = 'he_normal')(X)\n",
    "    X = ks.layers.BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = ks.layers.Activation('relu')(X)\n",
    "    \n",
    "\n",
    "    # Second \n",
    "    X = ks.layers.Conv2D(F2,(f,f),strides=(1,1),padding='same',name=conv_name_base+'2b',kernel_initializer='he_normal')(X)\n",
    "    X = ks.layers.BatchNormalization(axis=3,name=bn_name_base+'2b')(X)\n",
    "    X = ks.layers.Activation('relu')(X)\n",
    "\n",
    "    # Third \n",
    "    X = ks.layers.Conv2D(F3,(1,1),strides=(1,1),padding='same',name=conv_name_base+'2c',kernel_initializer='he_normal')(X)\n",
    "    X = ks.layers.BatchNormalization(axis=3,name=bn_name_base+'2c')(X)\n",
    "\n",
    "    # in order to make same shape\n",
    "    X_shortcut = ks.layers.Conv2D(F3,(1,1),strides=(s,s),name=conv_name_base+'1',kernel_initializer='he_normal')(X_shortcut)\n",
    "    X_shortcut = ks.layers.BatchNormalization(axis=3,name=bn_name_base+'1')(X_shortcut)\n",
    "\n",
    "    # Add shortcut\n",
    "    X = ks.layers.Add()([X_shortcut,X])\n",
    "    X = ks.layers.Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fs2WyNC6Plo9"
   },
   "outputs": [],
   "source": [
    " #input \n",
    "x_input = ks.layers.Input(shape=x_train.shape[1:])\n",
    "\n",
    "    \n",
    "# Zero-Padding\n",
    "X = ks.layers.ZeroPadding2D((3, 3))(x_input)\n",
    "    \n",
    "# Stage 1\n",
    "X = ks.layers.Conv2D(32, (7, 7), strides = (2, 2), name = 'conv1',kernel_initializer='he_normal')(X)\n",
    "X = ks.layers.BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "X = ks.layers.Activation('relu')(X)\n",
    "X = ks.layers.MaxPooling2D((2, 2), strides=(1, 1))(X)\n",
    "\n",
    "# Stage 2\n",
    "X = convolutional_block(X, f = 3, filters = [32, 32, 64], stage = 2, block='a', s = 1)\n",
    "X = identity_block(X, 3, [32, 32, 64], stage=2, block='b')\n",
    "X = identity_block(X, 3, [32, 32, 64], stage=2, block='c')\n",
    "\n",
    "\n",
    "# Stage 3 (≈4 lines)\n",
    "X = convolutional_block(X, f = 3, filters = [64, 64, 128], stage = 3, block='a', s = 2)\n",
    "X = identity_block(X, 3, [64, 64, 128], stage=3, block='b')\n",
    "X = identity_block(X, 3, [64, 64, 128], stage=3, block='c')\n",
    "X = identity_block(X, 3, [64, 64, 128], stage=3, block='d')\n",
    "\n",
    "# Stage 4 (≈6 lines)\n",
    "X = convolutional_block(X, f = 3, filters = [128, 128, 256], stage = 4, block='a', s = 2)\n",
    "X = identity_block(X, 3, [128, 128, 256], stage=4, block='b')\n",
    "X = identity_block(X, 3, [128, 128, 256], stage=4, block='c')\n",
    "X = identity_block(X, 3, [128, 128, 256], stage=4, block='d')\n",
    "X = identity_block(X, 3, [128, 128, 256], stage=4, block='e')\n",
    "X = identity_block(X, 3, [128, 128, 256], stage=4, block='f')\n",
    "\n",
    "# Stage 5 (≈3 lines)\n",
    "X = convolutional_block(X, f = 3, filters = [256, 256, 512], stage = 5, block='a', s = 2)\n",
    "X = identity_block(X, 3, [256, 256, 512], stage=5, block='b')\n",
    "X = identity_block(X, 3, [256, 256,512], stage=5, block='c')\n",
    "\n",
    "# AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "X = ks.layers.AveragePooling2D(pool_size=(2,2),name='avg_pool')(X)\n",
    "    \n",
    "\n",
    "# output layer\n",
    "X = ks.layers.Flatten()(X)\n",
    "X = ks.layers.Dense(y_train.shape[1], activation='softmax', name='fc' + str(y_train.shape[1]),kernel_initializer='he_normal')(X)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "id": "EBLIMfOKBZWq",
    "outputId": "e52b5d06-c4e1-462b-cf14-31f4e71186fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2813/2813 [==============================] - 85s 30ms/step - loss: 2.0917 - accuracy: 0.2364 - val_loss: 1.9055 - val_accuracy: 0.3158\n",
      "Epoch 2/10\n",
      "2813/2813 [==============================] - 85s 30ms/step - loss: 1.7443 - accuracy: 0.3658 - val_loss: 1.6924 - val_accuracy: 0.3976\n",
      "Epoch 3/10\n",
      "2813/2813 [==============================] - 84s 30ms/step - loss: 1.5577 - accuracy: 0.4385 - val_loss: 1.4892 - val_accuracy: 0.4580\n",
      "Epoch 4/10\n",
      "2813/2813 [==============================] - 86s 30ms/step - loss: 1.4091 - accuracy: 0.4935 - val_loss: 1.3270 - val_accuracy: 0.5262\n",
      "Epoch 5/10\n",
      "2813/2813 [==============================] - 85s 30ms/step - loss: 1.2847 - accuracy: 0.5433 - val_loss: 1.2867 - val_accuracy: 0.5346\n",
      "Epoch 6/10\n",
      "2813/2813 [==============================] - 86s 30ms/step - loss: 1.1709 - accuracy: 0.5838 - val_loss: 1.2832 - val_accuracy: 0.5436\n",
      "Epoch 7/10\n",
      "2813/2813 [==============================] - 88s 31ms/step - loss: 1.0785 - accuracy: 0.6174 - val_loss: 1.2359 - val_accuracy: 0.5690\n",
      "Epoch 8/10\n",
      "2813/2813 [==============================] - 91s 32ms/step - loss: 0.9791 - accuracy: 0.6539 - val_loss: 1.2085 - val_accuracy: 0.5800\n",
      "Epoch 9/10\n",
      "2813/2813 [==============================] - 91s 32ms/step - loss: 0.8832 - accuracy: 0.6861 - val_loss: 1.1896 - val_accuracy: 0.5922\n",
      "Epoch 10/10\n",
      "2813/2813 [==============================] - 91s 32ms/step - loss: 0.7921 - accuracy: 0.7230 - val_loss: 1.2759 - val_accuracy: 0.5830\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 1.2936 - accuracy: 0.5754\n"
     ]
    }
   ],
   "source": [
    "model = ks.Model(inputs = x_input, outputs = X, name='ResNet50')\n",
    "opt=ks.optimizers.RMSprop(learning_rate=0.0001)\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "histroy=model.fit(x_train,y_train,batch_size=16,epochs=10,validation_split=0.10)\n",
    "pred=model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "T0JGCE34Ad6W",
    "outputId": "768340f3-75ba-4f8e-8b9a-6467e90a2f89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 38, 38, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 16, 16, 32)   4736        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 16, 16, 32)   128         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 16, 16, 32)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 15, 15, 32)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 15, 15, 32)   1056        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 15, 15, 32)   128         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 15, 15, 32)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 15, 15, 32)   9248        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 15, 15, 32)   128         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 15, 15, 32)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 15, 15, 64)   2112        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 15, 15, 64)   2112        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 15, 15, 64)   256         res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 15, 15, 64)   256         res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 15, 15, 64)   0           bn2a_branch1[0][0]               \n",
      "                                                                 bn2a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 15, 15, 64)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 15, 15, 32)   2080        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 15, 15, 32)   128         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 15, 15, 32)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 15, 15, 32)   9248        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 15, 15, 32)   128         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 15, 15, 32)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 15, 15, 64)   2112        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 15, 15, 64)   256         res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 15, 15, 64)   0           activation_3[0][0]               \n",
      "                                                                 bn2b_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 15, 15, 64)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 15, 15, 32)   2080        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 15, 15, 32)   128         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 15, 15, 32)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 15, 15, 32)   9248        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 15, 15, 32)   128         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 15, 15, 32)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 15, 15, 64)   2112        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 15, 15, 64)   256         res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 15, 15, 64)   0           activation_6[0][0]               \n",
      "                                                                 bn2c_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 15, 15, 64)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 8, 8, 64)     4160        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 8, 8, 64)     0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 8, 8, 64)     0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 8, 8, 128)    8320        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 8, 8, 128)    8320        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 8, 8, 128)    512         res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 8, 8, 128)    512         res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 8, 8, 128)    0           bn3a_branch1[0][0]               \n",
      "                                                                 bn3a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 8, 8, 128)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 8, 8, 64)     8256        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8, 8, 64)     0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 64)     0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 8, 8, 128)    8320        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 8, 8, 128)    512         res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8, 8, 128)    0           activation_12[0][0]              \n",
      "                                                                 bn3b_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 128)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 8, 8, 64)     8256        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 64)     0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 64)     0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 8, 8, 128)    8320        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 8, 8, 128)    512         res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 8, 8, 128)    0           activation_15[0][0]              \n",
      "                                                                 bn3c_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 128)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 8, 8, 64)     8256        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 8, 64)     0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 8, 8, 64)     0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 8, 8, 128)    8320        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 8, 8, 128)    512         res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 128)    0           activation_18[0][0]              \n",
      "                                                                 bn3d_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 8, 8, 128)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 4, 4, 128)    16512       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 4, 4, 128)    0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 4, 4, 128)    0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 4, 4, 256)    33024       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 4, 4, 256)    33024       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 4, 4, 256)    1024        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 4, 4, 256)    1024        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 4, 4, 256)    0           bn4a_branch1[0][0]               \n",
      "                                                                 bn4a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 4, 4, 256)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 4, 4, 128)    32896       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 4, 4, 128)    0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 4, 4, 128)    0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 4, 4, 256)    33024       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 4, 4, 256)    1024        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 4, 4, 256)    0           activation_24[0][0]              \n",
      "                                                                 bn4b_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 4, 4, 256)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 4, 4, 128)    32896       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 4, 4, 128)    0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 4, 4, 128)    0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 4, 4, 256)    33024       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 4, 4, 256)    1024        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 4, 4, 256)    0           activation_27[0][0]              \n",
      "                                                                 bn4c_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 4, 4, 256)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 4, 4, 128)    32896       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 4, 4, 128)    0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 4, 4, 128)    0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 4, 4, 256)    33024       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 4, 4, 256)    1024        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 4, 4, 256)    0           activation_30[0][0]              \n",
      "                                                                 bn4d_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 4, 4, 256)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 4, 4, 128)    32896       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 4, 4, 128)    0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 4, 4, 128)    0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 4, 4, 256)    33024       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 4, 4, 256)    1024        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 4, 4, 256)    0           activation_33[0][0]              \n",
      "                                                                 bn4e_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 4, 4, 256)    0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 4, 4, 128)    32896       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 4, 4, 128)    0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 4, 4, 128)    0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 4, 4, 256)    33024       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 4, 4, 256)    1024        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 4, 4, 256)    0           activation_36[0][0]              \n",
      "                                                                 bn4f_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 4, 4, 256)    0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 2, 2, 256)    65792       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 2, 2, 256)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 2, 2, 256)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 2, 2, 512)    131584      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 2, 2, 512)    131584      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 2, 2, 512)    2048        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 2, 2, 512)    0           bn5a_branch1[0][0]               \n",
      "                                                                 bn5a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 2, 2, 512)    0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 2, 2, 256)    131328      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 2, 2, 256)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 2, 2, 256)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 2, 2, 512)    131584      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 2, 2, 512)    0           activation_42[0][0]              \n",
      "                                                                 bn5b_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 2, 2, 512)    0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 2, 2, 256)    131328      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 2, 2, 256)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 2, 2, 256)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 2, 2, 512)    131584      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 2, 2, 512)    0           activation_45[0][0]              \n",
      "                                                                 bn5c_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 2, 2, 512)    0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 1, 1, 512)    0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fc10 (Dense)                    (None, 10)           5130        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,226,378\n",
      "Trainable params: 4,209,290\n",
      "Non-trainable params: 17,088\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "sdOcOCJmtM38",
    "outputId": "7b048846-8931-40a3-dcc3-22c2b9af58f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f812a26b710>]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(121)\n",
    "plt.title('Cross Entropy Loss')\n",
    "plt.plot(histroy.history['loss'],label='Train')\n",
    "plt.plot(histroy.history['val_loss'],label='Validation')\n",
    "plt.legend()\n",
    "plt.subplot(122)\n",
    "plt.title('Classification Accuracy')\n",
    "plt.plot(histroy.history['accuracy'], color='blue', label='train')\n",
    "plt.plot(histroy.history['val_accuracy'], color='orange', label='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_aCtsxFNodjx"
   },
   "source": [
    "Here i have following architecture for CIFAR_10 datset classification:\n",
    "* ResNet50 Architecture which has 50 layers\n",
    "* No data augumentation\n",
    "* he_normal initalization for weights\n",
    "* batch_size=16\n",
    "* epoch =10\n",
    "---\n",
    "We got an decent accurancy training=0.72,validation=0.58,test=0.57 with very less epochs.Lets try different parameters with same underlying Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p0Cks45grXvf"
   },
   "outputs": [],
   "source": [
    "x_train_mean=x_train.mean(axis=0)\n",
    "x_train -=x_train_mean\n",
    "x_test -=x_train_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 874
    },
    "colab_type": "code",
    "id": "ClF0pWzMo4RR",
    "outputId": "0d6de12a-68c8-45fe-c18f-6072417917ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Epoch 1/25\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 1.0066 - accuracy: 0.6465 - val_loss: 1.0294 - val_accuracy: 0.6365\n",
      "Epoch 2/25\n",
      "1562/1562 [==============================] - 63s 41ms/step - loss: 0.9515 - accuracy: 0.6648 - val_loss: 1.0387 - val_accuracy: 0.6447\n",
      "Epoch 3/25\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.9215 - accuracy: 0.6765 - val_loss: 0.9784 - val_accuracy: 0.6586\n",
      "Epoch 4/25\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.8830 - accuracy: 0.6897 - val_loss: 0.9496 - val_accuracy: 0.6692\n",
      "Epoch 5/25\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.8512 - accuracy: 0.6972 - val_loss: 0.9275 - val_accuracy: 0.6845\n",
      "Epoch 6/25\n",
      "1562/1562 [==============================] - 65s 42ms/step - loss: 0.8305 - accuracy: 0.7086 - val_loss: 0.9426 - val_accuracy: 0.6669\n",
      "Epoch 7/25\n",
      "1562/1562 [==============================] - 68s 43ms/step - loss: 0.8082 - accuracy: 0.7157 - val_loss: 0.9386 - val_accuracy: 0.6786\n",
      "Epoch 8/25\n",
      "1562/1562 [==============================] - 68s 43ms/step - loss: 0.7847 - accuracy: 0.7241 - val_loss: 0.9103 - val_accuracy: 0.6914\n",
      "Epoch 9/25\n",
      "1562/1562 [==============================] - 67s 43ms/step - loss: 0.7618 - accuracy: 0.7322 - val_loss: 0.8953 - val_accuracy: 0.6865\n",
      "Epoch 10/25\n",
      "1562/1562 [==============================] - 68s 44ms/step - loss: 0.7388 - accuracy: 0.7376 - val_loss: 0.8734 - val_accuracy: 0.7023\n",
      "Epoch 11/25\n",
      "1562/1562 [==============================] - 68s 43ms/step - loss: 0.7215 - accuracy: 0.7470 - val_loss: 0.8605 - val_accuracy: 0.7038\n",
      "Epoch 12/25\n",
      "1562/1562 [==============================] - 67s 43ms/step - loss: 0.7023 - accuracy: 0.7546 - val_loss: 0.8597 - val_accuracy: 0.7087\n",
      "Epoch 13/25\n",
      "1562/1562 [==============================] - 66s 42ms/step - loss: 0.6854 - accuracy: 0.7575 - val_loss: 0.8438 - val_accuracy: 0.7145\n",
      "Epoch 14/25\n",
      "1562/1562 [==============================] - 65s 42ms/step - loss: 0.6650 - accuracy: 0.7674 - val_loss: 0.8679 - val_accuracy: 0.7094\n",
      "Epoch 15/25\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.6529 - accuracy: 0.7696 - val_loss: 0.8458 - val_accuracy: 0.7136\n",
      "Epoch 16/25\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.6269 - accuracy: 0.7798 - val_loss: 0.8365 - val_accuracy: 0.7189\n",
      "Epoch 17/25\n",
      "1562/1562 [==============================] - 65s 41ms/step - loss: 0.6175 - accuracy: 0.7822 - val_loss: 0.8378 - val_accuracy: 0.7221\n",
      "Epoch 18/25\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.6067 - accuracy: 0.7872 - val_loss: 0.8310 - val_accuracy: 0.7281\n",
      "Epoch 19/25\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.5895 - accuracy: 0.7919 - val_loss: 0.8123 - val_accuracy: 0.7262\n",
      "Epoch 20/25\n",
      "1562/1562 [==============================] - 65s 41ms/step - loss: 0.5736 - accuracy: 0.8009 - val_loss: 0.8304 - val_accuracy: 0.7234\n",
      "Epoch 21/25\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.5635 - accuracy: 0.7998 - val_loss: 0.8060 - val_accuracy: 0.7348\n",
      "Epoch 22/25\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.5532 - accuracy: 0.8053 - val_loss: 0.7971 - val_accuracy: 0.7410\n",
      "Epoch 23/25\n",
      "1562/1562 [==============================] - 64s 41ms/step - loss: 0.5347 - accuracy: 0.8115 - val_loss: 0.8026 - val_accuracy: 0.7384\n",
      "Epoch 24/25\n",
      "1562/1562 [==============================] - 63s 40ms/step - loss: 0.5205 - accuracy: 0.8149 - val_loss: 0.8527 - val_accuracy: 0.7289\n",
      "Epoch 25/25\n",
      "1562/1562 [==============================] - 65s 42ms/step - loss: 0.5156 - accuracy: 0.8174 - val_loss: 0.8261 - val_accuracy: 0.7372\n"
     ]
    }
   ],
   "source": [
    "data_augmentation = True\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=False,\n",
    "        # set each sample mean to 0\n",
    "        samplewise_center=False,\n",
    "        # divide inputs by std of dataset\n",
    "        featurewise_std_normalization=False,\n",
    "        # divide each input by its std\n",
    "        samplewise_std_normalization=False,\n",
    "        # apply ZCA whitening\n",
    "        zca_whitening=False,\n",
    "        # epsilon for ZCA whitening\n",
    "        zca_epsilon=1e-06,\n",
    "        # randomly rotate images in the range (deg 0 to 180)\n",
    "        rotation_range=0,\n",
    "        # randomly shift images horizontally\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically\n",
    "        height_shift_range=0.1,\n",
    "        # set range for random shear\n",
    "        shear_range=0.,\n",
    "        # set range for random zoom\n",
    "        zoom_range=0.,\n",
    "        # set range for random channel shifts\n",
    "        channel_shift_range=0.,\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        # value used for fill_mode = \"constant\"\n",
    "        cval=0.,\n",
    "        # randomly flip images\n",
    "        horizontal_flip=True,\n",
    "        # randomly flip images\n",
    "        vertical_flip=False,\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        epochs=25,workers=4,steps_per_epoch=len(x_train)//32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DMGc9n4P_jNf",
    "outputId": "0cbf481f-c5f0-4e0f-bba8-fb499b4c7f29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.8261 - accuracy: 0.7372\n"
     ]
    }
   ],
   "source": [
    "pred1=model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RhY7hv5J-nBZ"
   },
   "source": [
    "Here i have following architecture:\n",
    "* ResNet50 Architecture\n",
    "* data augumentation\n",
    "* he_normal initalization for weights\n",
    "* batch_size=32\n",
    "* epoch =25\n",
    "---\n",
    "We got an moderate good accurancy training=0.81,validation=0.73,test=0.73 with very less epochs. By having higher epochs we can achive great results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FkNqDAC151DG"
   },
   "source": [
    "**Answer 2**\n",
    "\n",
    "\n",
    "Regularization is a technique which prevents the learning algorithm from overfitting and improves the model’s performance.Regularization helps the learning alogirthm to generalize  on the unseen data well. Regularization in deep learning, penalizes the weight matrices of the layers.The main types of regularization technique are:\n",
    "\n",
    "1. L1 & L2 Regularization\n",
    "2. Dropout\n",
    "3. Data Augmentation\n",
    "4. Early Stopping\n",
    "\n",
    "L1 and L2 regularization update the general cost function by adding another term known as the regularization term.Due to the addition of this regularization term, the values of weight matrices decrease thus neural network with smaller weight matrices leads to simpler models. Therefore, it will also reduce overfitting to an extent.Dropout is the one of the most interesting types of regularization techniques. It also produces very good results and it is the most frequently used regularization technique in neural networks.At every iteration, it randomly selects some nodes and removes them along with all of their incoming and outgoing connections based on some probability.\n",
    "\n",
    "Data Augmentation is the simplest way to reduce overfitting and it is done by increasing the size of the training data.This usually provides a big leap in improving the accuracy of the model.Early stopping is a kind of cross-validation strategy where we keep one part of the training set as the validation set. When we see that the performance on the validation set is getting worse, we immediately stop the training on the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H8RJR4s37bD7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
